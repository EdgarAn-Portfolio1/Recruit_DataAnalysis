{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 깃허브에서 참고한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naver:\n",
    "    def __init__(self):\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        self.options.add_argument('headless')\n",
    "        self.driver = \"\"\n",
    "        self.url_list =[]\n",
    "        self.stop_crawling = True\n",
    "    def Open_Chrome(self, URL) :  \n",
    "        self.driver = webdriver.Chrome(\"/Users/sky/Downloads/chromedriver\",options=self.options)\n",
    "        self.driver.get(URL)\n",
    "        self.driver.implicitly_wait(3)\n",
    "    \n",
    "    def Close_Chrome(self):\n",
    "        self.driver.close()\n",
    "        \n",
    "    def get_url(self,xpath):\n",
    "        get_xpath= self.driver.find_element_by_xpath(xpath)\n",
    "        url =  get_xpath.get_attribute('href')\n",
    "        return url\n",
    "    \n",
    "    def loop_get_url(self, limit_num, save_file_name):\n",
    "        i = 1\n",
    "        j = 1\n",
    "        num = len(self.url_list)\n",
    "\n",
    "        while (j<=5) :\n",
    "            try :\n",
    "                xpath= '//*[@id=\"section_body\"]/ul[' + str(j) + ']/li[' + str(i) + ']/dl/dt[2]/a'\n",
    "                self.url_list.append(self.get_url(xpath))\n",
    "                i= i+1\n",
    "                num = num +1\n",
    "                if(num==limit_num):\n",
    "                    self.stop_crawling = False\n",
    "                    break\n",
    "            except:\n",
    "                i = 1\n",
    "                j = j+1\n",
    "        with open(save_file_name, 'wb') as f:\n",
    "            pickle.dump(self.url_list, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver = Naver()\n",
    "i = 1 \n",
    "while naver.stop_crawling:\n",
    "    print(\"current page : \",i)\n",
    "    url = 'https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=105#&date=%2000:00:00&page='+str(i)\n",
    "    naver.Open_Chrome(url)\n",
    "    naver.loop_get_url(1000,'it.pickle')\n",
    "    naver.Close_Chrome()\n",
    "    i = i+1\n",
    "    time.sleep(.5)\n",
    "    print(\"current list length: \",len(naver.url_list))\n",
    "print(len(naver.url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/Users/sky/class_python/practice/과학.pickle', 'rb') as f:\n",
    "\n",
    "    data = pickle.load(f, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL(참고코드)로 데이터 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "wd = webdriver.Chrome('/Users/sky/Downloads/chromedriver')\n",
    "\n",
    "naver = []\n",
    "\n",
    "for url in data:\n",
    "    wd.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(wd.page_source)\n",
    "    \n",
    "    news = {}\n",
    "    news['title']= soup.select('#articleTitle')[0].text\n",
    "    news['date'] = soup.select('#main_content > div.article_header > div.article_info > div > span')[0].text\n",
    "    news['link'] = soup.select('#main_content > div.article_header > div.article_info > div > a')[0].attrs['href']\n",
    "    news['content']= soup.select('#articleBodyContents')[0].text\n",
    "    \n",
    "    time.sleep(.5)\n",
    "    #break\n",
    "    naver.append(news)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "it_news = pd.DataFrame(naver)\n",
    "it_news.to_csv('it_news_1126.csv', encoding='utf8')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f8a298e880cf99c9c7a0b66a05672eb9bf2d8825a9da8d2e07c7170541f5baf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
